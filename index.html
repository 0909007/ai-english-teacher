<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI ì˜ì–´ ì„ ìƒë‹˜</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      margin: 20px;
    }
    #micButton {
      background-color: #4caf50;
      color: white;
      border: none;
      padding: 12px 24px;
      border-radius: 8px;
      font-size: 18px;
      cursor: pointer;
    }
    #micButton.listening {
      background-color: #d32f2f;
    }
    #result {
      white-space: pre-line;
      margin-top: 20px;
      font-size: 20px;
      border: 1px solid #ddd;
      padding: 15px;
      border-radius: 8px;
      display: inline-block;
      text-align: left;
      min-width: 300px;
      max-width: 600px;
    }
    img {
      width: 200px;
      border-radius: 16px;
      margin-top: 20px;
      object-fit: cover;
    }
    h1 {
      font-weight: bold;
      margin-bottom: 5px;
    }
  </style>
</head>
<body>
  <h1>ğŸ“ AI ì˜ì–´ ì„ ìƒë‹˜</h1>
  <img src="https://images.unsplash.com/photo-1508214751196-bcfd4ca60f91?auto=format&fit=crop&w=400&q=80" alt="AI ì„ ìƒë‹˜ ì‚¬ì§„" />
  <br />
  <button id="micButton">ğŸ¤ ë§í•˜ê¸° ì‹œì‘</button>

  <div id="result">ë‚´ ë§: <br />AI ì„ ìƒë‹˜:</div>

  <script>
    // ìŒì„± ì¸ì‹ ì„¤ì •
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.continuous = false;

    const resultDiv = document.getElementById("result");
    const micButton = document.getElementById("micButton");

    let listening = false;

    micButton.addEventListener("click", () => {
      if (!listening) {
        recognition.start();
      } else {
        recognition.stop();
      }
    });

    recognition.onstart = () => {
      listening = true;
      micButton.classList.add("listening");
      micButton.textContent = "ë“£ëŠ” ì¤‘...";
    };

    recognition.onend = () => {
      listening = false;
      micButton.classList.remove("listening");
      micButton.textContent = "ğŸ¤ ë§í•˜ê¸° ì‹œì‘";
    };

    recognition.onresult = async (event) => {
      const transcript = event.results[0][0].transcript;
      resultDiv.textContent = "ë‚´ ë§: " + transcript + "\nAI ì„ ìƒë‹˜: ...ì‘ë‹µ ëŒ€ê¸°ì¤‘...";

      // GPTì— ë©”ì‹œì§€ ë³´ë‚´ê¸°
      const messages = [
        { role: "system", content: "You are a helpful AI English teacher." },
        { role: "user", content: transcript },
      ];

      const reply = await fetchGPTResponse(messages);
      resultDiv.textContent = "ë‚´ ë§: " + transcript + "\nAI ì„ ìƒë‹˜: " + reply;
    };

    async function fetchGPTResponse(messages) {
      try {
        const response = await fetch("/api/gpt", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ messages }),
        });

        if (!response.ok) {
          const error = await response.json();
          console.error("GPT API error:", error);
          return "ì˜¤ë¥˜ ë°œìƒ: " + error.error;
        }

        const data = await response.json();
        return data.content;
      } catch (e) {
        console.error("Fetch error:", e);
        return "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë˜ëŠ” ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
      }
    }
  </script>
</body>
</html>
