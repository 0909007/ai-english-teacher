const micButton = document.getElementById('micButton');
const output = document.getElementById('output');
const response = document.getElementById('response');

// ìŒì„± ì¸ì‹ ê°ì²´ ìƒì„± (í¬ë¡¬ ê¸°ì¤€)
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();

recognition.lang = 'en-US';
recognition.interimResults = false;

recognition.onstart = () => {
  micButton.classList.add('listening');
  micButton.textContent = 'ğŸ”´ ë“£ëŠ” ì¤‘...';
};

recognition.onend = () => {
  micButton.classList.remove('listening');
  micButton.textContent = 'ğŸ¤ ë§í•˜ê¸° ì‹œì‘';
};

recognition.onerror = (event) => {
  micButton.classList.remove('listening');
  micButton.textContent = 'ğŸ¤ ë§í•˜ê¸° ì‹œì‘';
  output.textContent = 'ì—ëŸ¬ ë°œìƒ: ' + event.error;
};

recognition.onresult = async (event) => {
  const transcript = event.results[0][0].transcript;
  output.textContent = 'ë‹¹ì‹ : ' + transcript;

  // ì—¬ê¸°ì— OpenAI API í˜¸ì¶œí•˜ëŠ” ë¶€ë¶„ ë„£ê¸° (ì˜ˆì‹œ)
  // ì˜ˆ) const reply = await askOpenAI(transcript);
  // response.textContent = 'AI: ' + reply;
};

function startListening() {
  recognition.start();
}
